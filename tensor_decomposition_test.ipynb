{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shadialameddin/tensor_decomposition/blob/master/tensor_decomposition_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_quEpBUTTvg"
   },
   "source": [
    "http://tensorly.org/stable/auto_examples/index.html#general-examples\n",
    "\n",
    "https://github.com/tensorly/tensorly\n",
    "\n",
    "\n",
    "Sparse backend\n",
    "\n",
    "Kruskal-tensors have been renamed cp_tensors\n",
    "\n",
    "Matrix-product-state has now been renamed tensor-train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3DAy_TUQoSc",
    "outputId": "8f864662-289d-4a48-c253-342a4d5df0a4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -U tensorly --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tensor_decomposition') and not os.path.isfile('TensorDecomp.py'):\n",
    "    !git clone https://github.com/shadialameddin/tensor_decomposition.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd tensor_decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TensorDecomp import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of available decomposition types:\n",
    "\n",
    "decomp_list = ['svd', 'parafac', 'tucker', 'matrix_product_state', 'NMF','non_negative_parafac', 'clarkson_woodruff_transform']\n",
    "#### The Error Handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fro  = lambda  x, y : norm(x-y, ord='fro') / norm(x, ord='fro')\n",
    "err_L1   = lambda  x, y : norm(x-y, ord=1) / norm(x, ord=1)\n",
    "err_Linf = lambda  x, y : norm(x-y, ord=inf) / norm(x, ord=inf)\n",
    "err_Spec = lambda  x, y : norm(x-y, ord=2) / norm(x, ord=2)\n",
    "    \n",
    "normL = [err_fro, err_L1, err_Linf, err_Spec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngp, d, N = 8192, 6, 64\n",
    "\n",
    "tensor = np.random.rand(ngp, d, N)\n",
    "\n",
    "# two derived matrices of the tensor (unfolding)\n",
    "mat_repr1_tens = tensor.reshape(-1, N)\n",
    "mat_repr2_tens = tensor.reshape(ngp,-1)\n",
    "\n",
    "# a vector with appropriate dimension to perform operations\n",
    "vec = np.random.rand(N)\n",
    "\n",
    "# a matrix with appropriate dimensions to perform operations\n",
    "someMatrix = np.random.rand(ngp, d)\n",
    "someTensor = np.random.rand(ngp, d, d)\n",
    "\n",
    "### Some Tensor Operations ###\n",
    "\n",
    "# tensor x some vector\n",
    "tensVec = tensor@vec\n",
    "#tensVec = np.einsum('klm,m->kl',tensor,vec,optimize ='optimal')\n",
    "\n",
    "# tensor x some matrix\n",
    "tensMat = np.einsum('ilk,il->k', tensor, someMatrix, optimize='optimal')\n",
    "\n",
    "# tensor x some other tensor x tensor\n",
    "tensTenstens = np.einsum('ilk,ilm,imp->kp', tensor, someTensor, tensor, optimize='optimal')\n",
    "\n",
    "# matrix representation of a tensor x some vector\n",
    "matRepr1Vec = mat_repr1_tens@vec\n",
    "\n",
    "# matrix representation of tensor x some matrix\n",
    "matRepr1Mat = mat_repr1_tens.T@someMatrix.flatten()\n",
    "\n",
    "# matrix representations of a tensor x some tensor x matrix representations of a tensor\n",
    "matReprTensMatRepr = mat_repr1_tens.T @ blk_diag(someTensor) @ mat_repr1_tens\n",
    "\n",
    "### TIME MEASUREMENT OF TENSOR OPERATIONS ###\n",
    "n = 1000\n",
    "\n",
    "# time of tensor x some vector\n",
    "time_tensVec = timeit.timeit( lambda: tensor@vec, number = n)/n\n",
    "\n",
    "# time of tensor x some matrix\n",
    "time_tensMat = timeit.timeit(lambda:np.einsum('ilk,il->k', tensor, someMatrix, optimize='optimal'), number = n)/n\n",
    "\n",
    "# time of tensor x some other tensor x tensor\n",
    "time_tensTenstens = timeit.timeit( lambda:np.einsum('ilk,ilm,imp->kp', tensor, someTensor, tensor, optimize='optimal'), number = n)/n\n",
    "\n",
    "# time of matrix representation of a tensor x some vector\n",
    "time_matRepr1Vec = timeit.timeit( lambda: mat_repr1_tens@vec, number = n)/n\n",
    "\n",
    "# time of matrix representations of a tensor x some tensor x matrix representations of a tensor\n",
    "bsr = blk_diag(someTensor)\n",
    "time_matReprTensMatRepr = timeit.timeit( lambda:mat_repr1_tens.T @ bsr @ mat_repr1_tens, number = n)/n\n",
    "\n",
    "# time of matrix representation of tensor x some matrix\n",
    "flattedMat = someMatrix.flatten()\n",
    "time_matRepr1Mat = timeit.timeit( lambda: mat_repr1_tens.T@flattedMat, number = n)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49152, 4) (4,) (4, 64)\n"
     ]
    }
   ],
   "source": [
    "svd_rank = 4\n",
    "u, s, vt = svds(mat_repr1_tens, svd_rank)\n",
    "print(u.shape,s.shape,vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SVD Decomposition Time:\t 0.33516506500000104\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "svdDecTime = timeit.timeit((lambda: svds(mat_repr1_tens, svd_rank)), number=n)/n\n",
    "print(\"Average SVD Decomposition Time:\\t\", svdDecTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saving with SVD using 4 Rank:\t 0.9374173482259115\n"
     ]
    }
   ],
   "source": [
    "memSavSvd = (tensor.nbytes - sum(f.nbytes for f in [u,s,vt])) / tensor.nbytes\n",
    "print(f\"Memory saving with SVD using {svd_rank} Rank:\\t\", memSavSvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of the SVD Decomposition Error:\t 0.4835259718767076\n",
      "L1 Norm of the SVD Decomposition Error:\t\t 0.4933969306166816\n",
      "L infinity Norm of the SVD Decomposition Error:\t 0.47434485800537685\n",
      "Spectral Norm of the SVD Decomposition Error:\t 0.07397507988569225\n"
     ]
    }
   ],
   "source": [
    "mat_repr1_recons = u @ np.diag(s) @ vt\n",
    "svdFro, svdL1, svdLinf, svdSpec = [error(mat_repr1_tens, mat_repr1_recons) for error in normL ]\n",
    "\n",
    "print(\"Frobenius Norm of the SVD Decomposition Error:\\t\", svdFro)\n",
    "print(\"L1 Norm of the SVD Decomposition Error:\\t\\t\", svdL1)\n",
    "print(\"L infinity Norm of the SVD Decomposition Error:\\t\", svdLinf)\n",
    "print(\"Spectral Norm of the SVD Decomposition Error:\\t\", svdSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in Decomposed Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03851404548095698 0.03120988266612109 0.06183109065758405 0.016259326924530117\n",
      "0.0014837116795020846\n",
      "0.006810009339422171 0.0032648760197376346 0.003294731242948074 0.0011400090695291528\n"
     ]
    }
   ],
   "source": [
    "# svd of matrix representation of tensor x some vector\n",
    "svdMatReprVec = u @ (np.diag(s) @ (vt @ vec))\n",
    "\n",
    "# svd of matrix representation of tensor x some matrix\n",
    "svdMatReprMat = vt.T @ np.diag(s) @ ( u.T @ someMatrix.flatten())\n",
    "\n",
    "# svd of matrix representation of tensor x some Tensor x svd of matrix representation of tensor x some\n",
    "svdMatReprTenssvdMatRepr = vt.T @ np.diag(s) @ ( u.T @ bsr @ u) @ np.diag(s) @ vt\n",
    "\n",
    "svdDecVec_fro, svdDecVec_L1, svdDecVec_Linf, svdDecVec_L2 = [norm(tensVec,svdMatReprVec.reshape(tensVec.shape)) for norm in normL]\n",
    "print(svdDecVec_fro, svdDecVec_L1, svdDecVec_Linf, svdDecVec_L2)\n",
    "\n",
    "tensMat_svdMatReprMat_L2 = err_Spec(tensMat,svdMatReprMat)\n",
    "print(tensMat_svdMatReprMat_L2)\n",
    "\n",
    "svdMatReprTenssvdMatRepr_tensTenstens_fro, svdMatReprTenssvdMatRepr_tensTenstens_L1, svdMatReprTenssvdMatRepr_tensTenstens_Linf, svdMatReprTenssvdMatRepr_tensTenstens_L2 = [norm(tensTenstens,svdMatReprTenssvdMatRepr) for norm in normL]\n",
    "print(svdMatReprTenssvdMatRepr_tensTenstens_fro, svdMatReprTenssvdMatRepr_tensTenstens_L1, svdMatReprTenssvdMatRepr_tensTenstens_Linf, svdMatReprTenssvdMatRepr_tensTenstens_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Speed Up Measures in Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.309069101583687 8.378483428193217 10.968013773978704\n",
      "0.8469014950038061 27.740118756639024 23.493148046580714\n",
      "1.3634756116457225 8.127950480052762 11.082262252216085\n"
     ]
    }
   ],
   "source": [
    "# time of svd of matrix representation of tensor x some vector\n",
    "time_svdMatReprVec = timeit.timeit( lambda:u @ (np.diag(s) @ (vt @ vec)), number = n)/n\n",
    "\n",
    "# time of svd of matrix representation of tensor x some matrix\n",
    "time_svdMatReprMat = timeit.timeit( lambda:vt.T @ np.diag(s) @ ( u.T @ flattedMat), number = n)/n\n",
    "\n",
    "# time of svd of matrix representation of tensor x some Tensor x svd of matrix representation of tensor x some\n",
    "time_svdMatReprTenssvdMatRepr = timeit.timeit( lambda:vt.T @ np.diag(s) @ ( u.T @ bsr @ u) @ np.diag(s) @ vt, number = n)/n\n",
    "\n",
    "# Speed up in operations\n",
    "\n",
    "### \n",
    "speedup_tensVec_matReprVec = time_tensVec / time_matRepr1Vec\n",
    "speedup_matRepr1Vec_svdMatReprVec =  time_matRepr1Vec / time_svdMatReprVec\n",
    "speedup_tensVec_svdMatReprVec = time_tensVec / time_svdMatReprVec\n",
    "\n",
    "###\n",
    "speedup_tensMat_matRepr1Mat = time_tensMat / time_matRepr1Mat\n",
    "speedup_matRepr1Mat_svdMatReprMat = time_matRepr1Mat / time_svdMatReprMat\n",
    "speedup_tensMat_svdMatReprMat = time_tensMat / time_svdMatReprMat\n",
    "\n",
    "###\n",
    "speedup_tenstenstens_matReprTensMatRepr = time_tensTenstens / time_matReprTensMatRepr\n",
    "speedup_matReprTensMatRepr_svdMatReprTenssvdMatRepr = time_matReprTensMatRepr / time_svdMatReprTenssvdMatRepr \n",
    "speedup_tenstenstens_svdMatReprTenssvdMatRepr = time_tensTenstens / time_svdMatReprTenssvdMatRepr \n",
    "\n",
    "print(speedup_tensVec_matReprVec, speedup_matRepr1Vec_svdMatReprVec, speedup_tensVec_svdMatReprVec)\n",
    "print(speedup_tensMat_matRepr1Mat, speedup_matRepr1Mat_svdMatReprMat, speedup_tensMat_svdMatReprMat)\n",
    "print(speedup_tenstenstens_matReprTensMatRepr, speedup_matReprTensMatRepr_svdMatReprTenssvdMatRepr, speedup_tenstenstens_svdMatReprTenssvdMatRepr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core Dimension (4, 4, 4)\n",
      "Factors Dimensions [(8192, 4), (6, 4), (64, 4)]\n"
     ]
    }
   ],
   "source": [
    "rank_tucker = (4,4,4)\n",
    "core, factors = tucker(tensor, rank_tucker)\n",
    "print(\"Core Dimension\",core.shape)\n",
    "print(\"Factors Dimensions\", [f.shape for f in factors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tucker Decomposition Time:\t 0.33371259999999836\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "tuckerDecTime = timeit.timeit((lambda: tucker(tensor, rank_tucker)), number=n)/n\n",
    "print(\"Average Tucker Decomposition Time:\\t\", tuckerDecTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saving with Tucker Decomposition using (4, 4, 4) Rank:\t 0.9894739786783854\n"
     ]
    }
   ],
   "source": [
    "memSavTucker = (tensor.nbytes - (core.nbytes + sum(f.nbytes for f in factors))) / tensor.nbytes\n",
    "print(f\"Memory saving with Tucker Decomposition using {rank_tucker} Rank:\\t\", memSavTucker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of the Tucker Decomposition Error:\t 0.4972643293817595\n",
      "L1 Norm of the Tucker Decomposition Error:\t\t 0.4986058253910836\n",
      "L infinity Norm of the Tucker Decomposition Error:\t 0.48740765537207165\n",
      "Spectral Norm of the Tucker Decomposition Error:\t 0.07397590880680477\n"
     ]
    }
   ],
   "source": [
    "tensor_approx_tucker = np.einsum('lmn,il,jm,kn->ijk',core,factors[0],factors[1],factors[2])\n",
    "tuckerFro, tuckerL1, tuckerLinf, tuckerSpec = [error(tensor.reshape(-1,N), tensor_approx_tucker.reshape(-1,N)) for error in normL ]\n",
    "\n",
    "print(\"Frobenius Norm of the Tucker Decomposition Error:\\t\", tuckerFro)\n",
    "print(\"L1 Norm of the Tucker Decomposition Error:\\t\\t\", tuckerL1)\n",
    "print(\"L infinity Norm of the Tucker Decomposition Error:\\t\", tuckerLinf)\n",
    "print(\"Spectral Norm of the Tucker Decomposition Error:\\t\", tuckerSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposed Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposed tensor @ vec\n",
    "tuckerTens_Vec = np.einsum('klm,pk,rl,s->pr', core, factors[0], factors[1], factors[2].T @ vec)\n",
    "\n",
    "#parTensorVec = np.einsum('lmn,il,jm,kn->ijk',core,factors[0],factors[1],factors[2])\n",
    "\n",
    "# decomposed tensor @ mat\n",
    "tuckerTens_Mat = np.einsum('klm,pk,pl,rm->r', core, (someMatrix.T@factors[0]), factors[1], factors[2])\n",
    "\n",
    "# decomposed tensor @ someTensor @ decomposed tensor\n",
    "#tuckerTens_tensor_tuckerTens = np.einsum( optimize='optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error between decomposed tensor - matrix and tensor-matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375278411606076 0.09829092686605531 0.17989820114328656 0.05160795048221839\n",
      "0.0014743989065063138\n"
     ]
    }
   ],
   "source": [
    "tuckerTensVec_fro, tuckerTensVec_L1, tuckerTensVec_Linf, tuckerTensVec_L2 = [error(tensVec, tuckerTens_Vec ) for error in normL]\n",
    "\n",
    "print(tuckerTensVec_fro, tuckerTensVec_L1, tuckerTensVec_Linf, tuckerTensVec_L2)\n",
    "\n",
    "tuckerTensMat_L2 = err_Spec(tensMat, tuckerTens_Mat) \n",
    "\n",
    "print(tuckerTensMat_L2)\n",
    "\n",
    "#parTensTens_fro, parTensTens_L1, parTensTens_Linf, parTensTens_L2 = [error(tensTenstens, parTensTens) for error in normL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Speed Up Measures in Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 100\n",
    "\n",
    "# time of tucker tensor x some vector\n",
    "time_tuckerTens_Vec = timeit.timeit(lambda:np.einsum('klm,pk,rl,s->pr', core, factors[0], factors[1], factors[2].T @ vec, optimize ='optimal'), number = n)/n\n",
    "\n",
    "# time of tucker tensor x some matrix\n",
    "time_tuckerTens_Mat = timeit.timeit( lambda:np.einsum('klm,pk,pl,rm->r', core, (someMatrix.T@factors[0]), factors[1], factors[2],optimize ='optimal'), number = n)/n\n",
    "\n",
    "# time of tucker tensor x some Tensor x tucker tensor\n",
    "#time_parTens_tensor_parTens = timeit.timeit( lambda:vt.T @ np.diag(s) @ ( u.T @ blk_diag(someTensor) @ u) @ np.diag(s) @ vt, number = n)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.539938834374007 5.231181127909286\n"
     ]
    }
   ],
   "source": [
    "speedUP_tensVec_tuckerTensVec = time_tensVec / time_tuckerTens_Vec\n",
    "speedUP_tensMat_tuckerTensMat = time_tensMat / time_tuckerTens_Mat\n",
    "#speedUP_tensTensortens_parTensTensorParTens = time_tensTenstens / time_time_parTens_tensor_parTens\n",
    "\n",
    "print(speedUP_tensVec_tuckerTensVec,speedUP_tensMat_tuckerTensMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafac Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parafac weight dimension:\t (4,)\n",
      "Parafac factors dimension:\t [(8192, 4), (6, 4), (64, 4)]\n"
     ]
    }
   ],
   "source": [
    "rank_parafac = 4\n",
    "weight, factors = parafac(tensor, rank_parafac)\n",
    "\n",
    "print(\"Parafac weight dimension:\\t\",weight.shape)\n",
    "print(\"Parafac factors dimension:\\t\", [f.shape for f in factors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Parafac Decomposition Time:\t 8.291404765\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "parDecTime = timeit.timeit((lambda: parafac(tensor, rank_parafac)), number=n)/n\n",
    "print(\"Average Parafac Decomposition Time:\\t\", parDecTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saving with SVD using 4 Rank:\t 0.9894930521647135\n"
     ]
    }
   ],
   "source": [
    "parMemSav = (tensor.nbytes - (weight.nbytes + sum(f.nbytes for f in factors))) / tensor.nbytes\n",
    "print(f\"Memory saving with SVD using {svd_rank} Rank:\\t\", parMemSav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of the Parafac Decomposition Error:\t 0.4971923864140648\n",
      "L1 Norm of the Parafac Decomposition Error:\t\t 0.49776092766254454\n",
      "L infinity Norm of the Parafac Decomposition Error:\t 0.487678129450437\n",
      "Spectral Norm of the Parafac Decomposition Error:\t 0.07425268067674642\n"
     ]
    }
   ],
   "source": [
    "tensor_approx_parafac = np.einsum('il,jl,kl->ijk',(factors[0]*weight),factors[1],factors[2])\n",
    "parFro, parL1, parLinf, parSpec = [error(tensor.reshape(-1,N), tensor_approx_parafac.reshape(-1,N)) for error in normL ]\n",
    "\n",
    "print(\"Frobenius Norm of the Parafac Decomposition Error:\\t\", parFro)\n",
    "print(\"L1 Norm of the Parafac Decomposition Error:\\t\\t\", parL1)\n",
    "print(\"L infinity Norm of the Parafac Decomposition Error:\\t\", parLinf)\n",
    "print(\"Spectral Norm of the Parafac Decomposition Error:\\t\", parSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposed Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposed tensor @ vec\n",
    "parTens_Vec = np.einsum('il,jl,l->ij',(factors[0]*weight),factors[1],factors[2].T @ vec)\n",
    "\n",
    "# decomposed tensor @ mat\n",
    "parTens_Mat = np.einsum('k,mn,op->o', ((someMatrix.T@factors[0])@weight), factors[1], factors[2])\n",
    "\n",
    "\n",
    "# decomposed tensor @ someTensor @ decomposed tensor\n",
    "#parTens_tensor_parTens = np.einsum( optimize='optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error between decomposed tensor - matrix and tensor-matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375278411606076 0.09829092686605531 0.17989820114328656 0.05160795048221839\n",
      "0.0014743989065063138\n"
     ]
    }
   ],
   "source": [
    "parTensVec_fro, parTensVec_L1, parTensVec_Linf, parTensVec_L2 = [error(tensVec, parTens_Vec ) for error in normL]\n",
    "\n",
    "print(tuckerTensVec_fro, tuckerTensVec_L1, tuckerTensVec_Linf, tuckerTensVec_L2)\n",
    "\n",
    "parTensMat_L2 = err_Spec(tensMat, parTens_Mat) \n",
    "\n",
    "print(tuckerTensMat_L2)\n",
    "\n",
    "#parTensTens_fro, parTensTens_L1, parTensTens_Linf, parTensTens_L2 = [error(tensTenstens, parTensTens) for error in normL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Speed Up Measures in Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "\n",
    "# time of tucker tensor x some vector\n",
    "time_parTens_Vec = timeit.timeit(lambda:np.einsum('il,jl,l->ij',(factors[0]*weight),factors[1],factors[2].T @ vec, optimize ='optimal'), number = n)/n\n",
    "\n",
    "# time of tucker tensor x some matrix\n",
    "time_parTens_Mat = timeit.timeit( lambda:np.einsum('k,mn,op->o', ((someMatrix.T@factors[0])@weight), factors[1], factors[2],optimize ='optimal'), number = n)/n\n",
    "\n",
    "# time of tucker tensor x some Tensor x tucker tensor\n",
    "#time_parTens_tensor_parTens = timeit.timeit( lambda:vt.T @ np.diag(s) @ ( u.T @ blk_diag(someTensor) @ u) @ np.diag(s) @ vt, number = n)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.03334103110004 17.606639143804976\n"
     ]
    }
   ],
   "source": [
    "speedUP_tensVec_parTensVec = time_tensVec / time_parTens_Vec\n",
    "speedUP_tensMat_parTensMat = time_tensMat / time_parTens_Mat\n",
    "#speedUP_tensTensortens_parTensTensorParTens = time_tensTenstens / time_time_parTens_tensor_parTens\n",
    "\n",
    "print(speedUP_tensVec_parTensVec,speedUP_tensMat_parTensMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Train (matrix product state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Train factors dimension:\t [(1, 8192, 3), (3, 6, 3), (3, 64, 1)]\n"
     ]
    }
   ],
   "source": [
    "rank_tt = 3\n",
    "factors = matrix_product_state(tensor, (1,rank_tt,rank_tt,1))\n",
    "print(\"Tensor Train factors dimension:\\t\", [f.shape for f in factors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tensor Train Decomposition Time:\t 0.04440389600000003\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "ttDecTime = timeit.timeit((lambda: matrix_product_state(tensor, (1,rank_tt,rank_tt,1))), number=n)/n\n",
    "print(\"Average Tensor Train Decomposition Time:\\t\", ttDecTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saving with Tensor Train Decomposition using 3 Rank:\t 0.9921092987060547\n"
     ]
    }
   ],
   "source": [
    "memSavTT = (tensor.nbytes - sum(f.nbytes for f in factors)) / tensor.nbytes\n",
    "print(f\"Memory saving with Tensor Train Decomposition using {rank_tt} Rank:\\t\", memSavTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius Norm of the Tensor Train Decomposition Error:\t\t 0.49896153354963757\n",
      "L1 Norm of the Tensor Train Decomposition Error:\t\t 0.4992381027806814\n",
      "L infinity Norm of the Tensor Train Decomposition Error:\t 0.4895861413307165\n",
      "Spectral Norm of the Tensor Train Decomposition Error:\t\t 0.07437581623841272\n"
     ]
    }
   ],
   "source": [
    "tensor_approx_tt = np.einsum('nil,ljm,mkn->ijk',factors[0],factors[1],factors[2])\n",
    "ttFro, ttL1, ttLinf, ttSpec = [error(tensor.reshape(-1,N), tensor_approx_tt.reshape(-1,N)) for error in normL ]\n",
    "\n",
    "print(\"Frobenius Norm of the Tensor Train Decomposition Error:\\t\\t\", ttFro)\n",
    "print(\"L1 Norm of the Tensor Train Decomposition Error:\\t\\t\", ttL1)\n",
    "print(\"L infinity Norm of the Tensor Train Decomposition Error:\\t\", ttLinf)\n",
    "print(\"Spectral Norm of the Tensor Train Decomposition Error:\\t\\t\", ttSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposed Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposed tensor @ vec\n",
    "ttTens_Vec = np.einsum('bcd, kl->cl', factors[0],(factors[1] @ np.einsum('ijk,j->i', factors[2], vec, optimize = 'optimal')), optimize = 'optimal')\n",
    "\n",
    "\n",
    "# decomposed tensor @ mat\n",
    "#ttTens_Mat = np.einsum('bcd,mjm,mol->o',a,factors[1],factors[2])\n",
    "\n",
    "# decomposed tensor @ someTensor @ decomposed tensor\n",
    "#tuckerTens_tensor_tuckerTens = np.einsum( optimize='optimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error between decomposed tensor - matrix and tensor-matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375278411606076 0.09829092686605531 0.17989820114328656 0.05160795048221839\n"
     ]
    }
   ],
   "source": [
    "ttTensVec_fro, ttTensVec_L1, ttTensVec_Linf, ttTensVec_L2 = [error(tensVec, ttTens_Vec ) for error in normL]\n",
    "\n",
    "print(tuckerTensVec_fro, tuckerTensVec_L1, tuckerTensVec_Linf, tuckerTensVec_L2)\n",
    "\n",
    "#ttTensMat_L2 = err_Spec(tensMat,c) \n",
    "\n",
    "#print(ttTensMat_L2)\n",
    "\n",
    "#parTensTens_fro, parTensTens_L1, parTensTens_Linf, parTensTens_L2 = [error(tensTenstens, parTensTens) for error in normL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Speed Up Measures in Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 100\n",
    "\n",
    "# time of tucker tensor x some vector\n",
    "time_ttTens_Vec = timeit.timeit(lambda:np.einsum('bcd, kl->cl', factors[0],(factors[1] @ np.einsum('ijk,j->i', factors[2], vec, optimize = 'optimal')), optimize ='optimal'), number = n)/n\n",
    "\n",
    "# time of tucker tensor x some matrix\n",
    "#time_ttTens_Mat = timeit.timeit()\n",
    "# time of tucker tensor x some Tensor x tucker tensor\n",
    "#time_ttTens_tensor_ttTens = timeit.timeit( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.539938834374007\n"
     ]
    }
   ],
   "source": [
    "speedUP_tensVec_ttTensVec = time_tensVec / time_ttTens_Vec\n",
    "#speedUP_tensMat_tuckerTensMat = time_tensMat / time_tuckerTens_Mat\n",
    "#speedUP_tensTensortens_parTensTensorParTens = time_tensTenstens / time_time_parTens_tensor_parTens\n",
    "\n",
    "print(speedUP_tensVec_tuckerTensVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non negative parafac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposed Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error between decomposed tensor - matrix and tensor-matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition Speed Up Measures in Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errTucker = errList(tensor, tucker, vecR, vecL, matR, matL, normL, rank=[128,64,6])\n",
    "timeTucker = tensor.decomp_time\n",
    "memSavTucker = tensor.memSaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errParafac = errList(tensor, parafac, vecR, vecL, matR, matL, normL, rank=384)\n",
    "timeParafac = tensor.decomp_time\n",
    "memSavParafac = tensor.memSaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errTT  = errList(tensor, matrix_product_state, vecR, vecL, matR, matL, normL, rank=[1,128,128,1])\n",
    "timeTT = tensor.decomp_time\n",
    "memSavTT = tensor.memSaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errNNP  = errList(tensor, non_negative_parafac, vecR, vecL, matR, matL, normL, rank= 384)\n",
    "timeNNP = tensor.decomp_time\n",
    "memSavNNP = tensor.memSaving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "xAxis = ['SVD', 'Tucker', 'Parafac', 'Tensor Train', 'Non-negative Parafac']\n",
    "y0Axis = [errSvd[0][0], errTucker[0][0], errParafac[0][0], errTT[0][0], errNNP[0][0]]\n",
    "y1Axis = [timeSvd, timeTucker, timeParafac, timeTT, timeNNP]\n",
    "y2Axis = [memSavSvd, memSavTucker, memSavParafac, memSavTT, memSavNNP]\n",
    "colors = [\"crimson\",\"deepskyblue\", \"yellowgreen\"]\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(20,16), sharex=True)\n",
    "for i in range(3):\n",
    "    ax[i].bar(xAxis, eval('y'+str(i)+'Axis'), color=colors[i])\n",
    "    ax[i].yaxis.grid(color='b', alpha=0.5, linestyle='dashed', linewidth=0.5)\n",
    "    ax[i].set_axisbelow(True)\n",
    "    ax[i].set_ylim(0, np.ceil(max(eval('y'+str(i)+'Axis'))) + np.mean(eval('y'+str(i)+'Axis'))) if max(eval('y'+str(i)+'Axis')) > 0 else ax[i].set_ylim(0, np.floor(min(eval('y'+str(i)+'Axis')))-5)\n",
    "    ax[i].tick_params(axis='both', which='major', labelsize=16)\n",
    "    for h, v in enumerate(eval('y'+str(i)+'Axis')):\n",
    "        ax[i].text(h-.10, v+.0125, str(np.round(v,4)), color='black', size = 16, weight = \"bold\")\n",
    "\n",
    "plt.xlabel(\"Decomposition Types\", fontsize=24)\n",
    "ax[0].set_ylabel(\"Relative Error [-]\", fontsize=18)\n",
    "ax[1].set_ylabel(\"Time [sec]\", fontsize=18)\n",
    "ax[2].set_ylabel(\"Memory Saving [-]\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operList = [lambda:tensor.tensor@vecR, lambda:vecL@tensor.tensor, lambda:tensor.tensor@matR, lambda:matL@tensor.tensor, lambda:vecL@tensor.tensor@vecR, \n",
    "lambda:matL@tensor.tensor@matR]\n",
    "\n",
    "tensorOperationTimes = tensOpTim(operList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "uniSlightBlue = '#00BEFF'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20,8))\n",
    "ax.bar(operList, tensorOperationTimes, color = uniSlightBlue)\n",
    "ax.yaxis.grid(color='b', alpha=0.5, linestyle='dashed', linewidth=0.5)\n",
    "plt.xticks(rotation=22.5)\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_ylabel(\"Elapsed Time [sec]\", fontsize=24)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True) \n",
    "formatter.set_powerlimits((-1,1)) \n",
    "ax.yaxis.set_major_formatter(formatter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO #1\n",
    "# Speed comparion is not implemented. No function definition is defined for decomposed_tensor @ Vec multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO #2\n",
    "# For every decomposition type -> Line Plot: decomposition error, speedup time in tensor operations vs decomposed tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE! (11.07.21)\n",
    "# For every decomposition type -> Bar plot: Decomposition error, decomposition time, memory saving"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "tensor_decomposition_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
